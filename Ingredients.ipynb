{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOPYR2MetYab",
        "outputId": "48e6caaa-cf34-4b54-e569-426f4abdc9ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "drive_link = '/content/drive/My Drive/openfoodfacts.tsv'\n",
        "\n",
        "# Specify tab as the separator\n",
        "input_file = pd.read_csv(drive_link, sep='\\t', low_memory=False)\n",
        "\n",
        "print(\"File loaded.\")\n",
        "print(input_file.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpTzYmXzX0h0",
        "outputId": "1e95e883-2d2c-4ce4-b209-dbbe467cc0f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File loaded.\n",
            "            code                                                url  \\\n",
            "0  0000000003087  http://world-en.openfoodfacts.org/product/0000...   \n",
            "1  0000000004530  http://world-en.openfoodfacts.org/product/0000...   \n",
            "2  0000000004559  http://world-en.openfoodfacts.org/product/0000...   \n",
            "3  0000000016087  http://world-en.openfoodfacts.org/product/0000...   \n",
            "4  0000000016094  http://world-en.openfoodfacts.org/product/0000...   \n",
            "\n",
            "                      creator   created_t      created_datetime  \\\n",
            "0  openfoodfacts-contributors  1474103866  2016-09-17T09:17:46Z   \n",
            "1             usda-ndb-import  1489069957  2017-03-09T14:32:37Z   \n",
            "2             usda-ndb-import  1489069957  2017-03-09T14:32:37Z   \n",
            "3             usda-ndb-import  1489055731  2017-03-09T10:35:31Z   \n",
            "4             usda-ndb-import  1489055653  2017-03-09T10:34:13Z   \n",
            "\n",
            "  last_modified_t last_modified_datetime                    product_name  \\\n",
            "0      1474103893   2016-09-17T09:18:13Z              Farine de blé noir   \n",
            "1      1489069957   2017-03-09T14:32:37Z  Banana Chips Sweetened (Whole)   \n",
            "2      1489069957   2017-03-09T14:32:37Z                         Peanuts   \n",
            "3      1489055731   2017-03-09T10:35:31Z          Organic Salted Nut Mix   \n",
            "4      1489055653   2017-03-09T10:34:13Z                 Organic Polenta   \n",
            "\n",
            "  generic_name quantity  ... fruits-vegetables-nuts_100g  \\\n",
            "0          NaN      1kg  ...                         NaN   \n",
            "1          NaN      NaN  ...                         NaN   \n",
            "2          NaN      NaN  ...                         NaN   \n",
            "3          NaN      NaN  ...                         NaN   \n",
            "4          NaN      NaN  ...                         NaN   \n",
            "\n",
            "  fruits-vegetables-nuts-estimate_100g collagen-meat-protein-ratio_100g  \\\n",
            "0                                  NaN                              NaN   \n",
            "1                                  NaN                              NaN   \n",
            "2                                  NaN                              NaN   \n",
            "3                                  NaN                              NaN   \n",
            "4                                  NaN                              NaN   \n",
            "\n",
            "  cocoa_100g chlorophyl_100g carbon-footprint_100g nutrition-score-fr_100g  \\\n",
            "0        NaN             NaN                   NaN                     NaN   \n",
            "1        NaN             NaN                   NaN                    14.0   \n",
            "2        NaN             NaN                   NaN                     0.0   \n",
            "3        NaN             NaN                   NaN                    12.0   \n",
            "4        NaN             NaN                   NaN                     NaN   \n",
            "\n",
            "  nutrition-score-uk_100g glycemic-index_100g water-hardness_100g  \n",
            "0                     NaN                 NaN                 NaN  \n",
            "1                    14.0                 NaN                 NaN  \n",
            "2                     0.0                 NaN                 NaN  \n",
            "3                    12.0                 NaN                 NaN  \n",
            "4                     NaN                 NaN                 NaN  \n",
            "\n",
            "[5 rows x 163 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L-OTTv-vQH_",
        "outputId": "764d36a7-fccf-4aef-f765-81099ec2e842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion completed. Saved as: output.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "drive_link = '/content/drive/My Drive/openfoodfacts.tsv'\n",
        "output_file = 'output.csv'\n",
        "\n",
        "df = pd.read_csv(drive_link, sep='\\t', low_memory=False)\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Conversion completed. Saved as: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# === FOOD SAFETY ENSEMBLE MODEL - UPDATED FOR OUTPUT.CSV ===\n",
        "# =============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# =============================================================\n",
        "# 1. Load Dataset\n",
        "# =============================================================\n",
        "print(\"Loading dataset...\")\n",
        "df = pd.read_csv(\"/content/output.csv\", low_memory=False)\n",
        "print(\"Total rows:\", len(df))\n",
        "\n",
        "# =============================================================\n",
        "# 2. Basic Cleaning and Label Generation\n",
        "# =============================================================\n",
        "\n",
        "# Use nutrition-score-fr_100g as a health proxy\n",
        "df = df[~df[\"nutrition-score-fr_100g\"].isna()].copy()\n",
        "\n",
        "# Convert to numeric (force errors to NaN)\n",
        "df[\"nutrition-score-fr_100g\"] = pd.to_numeric(df[\"nutrition-score-fr_100g\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"nutrition-score-fr_100g\"])\n",
        "\n",
        "# Create categorical safety labels\n",
        "# NutriScore ranges: -15 (best) to +40 (worst)\n",
        "def label_from_nutriscore(score):\n",
        "    if score <= 0:\n",
        "        return \"Very Healthy\"\n",
        "    elif score <= 5:\n",
        "        return \"Healthy\"\n",
        "    elif score <= 15:\n",
        "        return \"Less Healthy\"\n",
        "    else:\n",
        "        return \"Unhealthy\"\n",
        "\n",
        "df[\"label\"] = df[\"nutrition-score-fr_100g\"].apply(label_from_nutriscore)\n",
        "\n",
        "# =============================================================\n",
        "# 3. Feature Selection\n",
        "# =============================================================\n",
        "\n",
        "feature_cols = [\n",
        "    \"energy_100g\", \"fat_100g\", \"saturated-fat_100g\",\n",
        "    \"carbohydrates_100g\", \"sugars_100g\", \"fiber_100g\",\n",
        "    \"proteins_100g\", \"salt_100g\", \"sodium_100g\"\n",
        "]\n",
        "\n",
        "# Ensure all features exist\n",
        "for col in feature_cols:\n",
        "    if col not in df.columns:\n",
        "        df[col] = np.nan\n",
        "\n",
        "df = df.dropna(subset=feature_cols)\n",
        "df = df.fillna(0)\n",
        "\n",
        "# Encode labels\n",
        "label_map = {\"Unhealthy\": 0, \"Less Healthy\": 1, \"Healthy\": 2, \"Very Healthy\": 3}\n",
        "df[\"label_encoded\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "# Shuffle for balanced learning\n",
        "df = shuffle(df, random_state=42)\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"label_encoded\"]\n",
        "\n",
        "# =============================================================\n",
        "# 4. Split Data\n",
        "# =============================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining on {len(X_train)} samples...\")\n",
        "print(\"Label distribution:\", np.bincount(y_train))\n",
        "\n",
        "# =============================================================\n",
        "# 5. Model 1 - LightGBM\n",
        "# =============================================================\n",
        "print(\"\\nTraining LightGBM...\")\n",
        "lgb_model = lgb.LGBMClassifier(objective=\"multiclass\", num_class=4, n_estimators=200)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "acc_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "print(\"LightGBM Test Accuracy:\", round(acc_lgb, 4))\n",
        "\n",
        "# =============================================================\n",
        "# 6. Model 2 - Hybrid Neural Network\n",
        "# =============================================================\n",
        "print(\"\\nTraining Hybrid Neural Network...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "hybrid_nn = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "hybrid_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hybrid_nn.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "acc_nn = hybrid_nn.evaluate(X_test_scaled, y_test, verbose=0)[1]\n",
        "print(\"Hybrid NN Test Accuracy:\", round(acc_nn, 4))\n",
        "\n",
        "# =============================================================\n",
        "# 7. Model 3 - Logistic Regression\n",
        "# =============================================================\n",
        "print(\"\\nTraining Logistic Regression...\")\n",
        "log_reg = LogisticRegression(max_iter=200)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "acc_lr = accuracy_score(y_test, log_reg.predict(X_test_scaled))\n",
        "print(\"Logistic Regression Test Accuracy:\", round(acc_lr, 4))\n",
        "\n",
        "# =============================================================\n",
        "# 8. Meta-Learner (Stacked Ensemble)\n",
        "# =============================================================\n",
        "print(\"\\nTraining Meta-Learner (Stacking)...\")\n",
        "\n",
        "train_meta = np.column_stack([\n",
        "    lgb_model.predict_proba(X_train),\n",
        "    hybrid_nn.predict(X_train_scaled),\n",
        "    log_reg.predict_proba(X_train_scaled)\n",
        "])\n",
        "\n",
        "test_meta = np.column_stack([\n",
        "    lgb_model.predict_proba(X_test),\n",
        "    hybrid_nn.predict(X_test_scaled),\n",
        "    log_reg.predict_proba(X_test_scaled)\n",
        "])\n",
        "\n",
        "meta_model = lgb.LGBMClassifier(objective=\"multiclass\", num_class=4)\n",
        "meta_model.fit(train_meta, y_train)\n",
        "acc_meta = accuracy_score(y_test, meta_model.predict(test_meta))\n",
        "print(\"Meta-Learner (Stack) Test Accuracy:\", round(acc_meta, 4))\n",
        "\n",
        "# =============================================================\n",
        "# 9. Final Blended Model Evaluation\n",
        "# =============================================================\n",
        "blend_probs = (\n",
        "    0.4 * lgb_model.predict_proba(X_test)\n",
        "    + 0.4 * hybrid_nn.predict(X_test_scaled)\n",
        "    + 0.2 * log_reg.predict_proba(X_test_scaled)\n",
        ")\n",
        "blend_preds = np.argmax(blend_probs, axis=1)\n",
        "acc_blend = accuracy_score(y_test, blend_preds)\n",
        "print(\"Blended Model Test Accuracy:\", round(acc_blend, 4))\n",
        "\n",
        "# =============================================================\n",
        "# 10. Print Summary\n",
        "# =============================================================\n",
        "print(\"\\n==================================================\")\n",
        "print(\"TRAINING COMPLETE - Model Performance Summary\")\n",
        "print(\"==================================================\")\n",
        "print(f\"LightGBM:              {acc_lgb:.4f}\")\n",
        "print(f\"Hybrid NN:             {acc_nn:.4f}\")\n",
        "print(f\"Logistic Regression:   {acc_lr:.4f}\")\n",
        "print(f\"Meta-Learner (Stack):  {acc_meta:.4f}\")\n",
        "print(f\"Blended Average:       {acc_blend:.4f}\")\n",
        "print(\"==================================================\")\n",
        "\n",
        "# =============================================================\n",
        "# 11. Safety Prediction Function\n",
        "# =============================================================\n",
        "def predict_safety(product_name, ingredients_text, energy, fat, sat_fat, carbs, sugars, fiber, protein, salt, sodium):\n",
        "    features = pd.DataFrame([{\n",
        "        \"energy_100g\": energy,\n",
        "        \"fat_100g\": fat,\n",
        "        \"saturated-fat_100g\": sat_fat,\n",
        "        \"carbohydrates_100g\": carbs,\n",
        "        \"sugars_100g\": sugars,\n",
        "        \"fiber_100g\": fiber,\n",
        "        \"proteins_100g\": protein,\n",
        "        \"salt_100g\": salt,\n",
        "        \"sodium_100g\": sodium\n",
        "    }])\n",
        "\n",
        "    X_scaled = scaler.transform(features)\n",
        "\n",
        "    probs = (\n",
        "        0.4 * lgb_model.predict_proba(features)\n",
        "        + 0.4 * hybrid_nn.predict(X_scaled)\n",
        "        + 0.2 * log_reg.predict_proba(X_scaled)\n",
        "    )\n",
        "\n",
        "    pred_class = np.argmax(probs)\n",
        "    pred_prob = np.max(probs)\n",
        "\n",
        "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "    category = reverse_label_map[pred_class]\n",
        "\n",
        "    # Convert to safety score (0–10)\n",
        "    safety_score = probs[0][3] * 10  # Probability of 'Very Healthy'\n",
        "    safety_score = round(float(np.clip(safety_score, 0, 10)), 2)\n",
        "\n",
        "    print(f\"\\n=== EXAMPLE PREDICTION ===\")\n",
        "    print(f\"Product: {product_name}\")\n",
        "    print(f\"Predicted Category: {category}\")\n",
        "    print(f\"Model Confidence: {pred_prob:.3f}\")\n",
        "    print(f\"Safety Score: {safety_score}/10\")\n",
        "\n",
        "    return category, safety_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFFyTqOQeHbm",
        "outputId": "88698d1e-ab49-4bc4-9b4f-def9a303209e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Total rows: 356027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2042414225.py:65: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df = df.fillna(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on 157728 samples...\n",
            "Label distribution: [39917 52105 27868 37838]\n",
            "\n",
            "Training LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2294\n",
            "[LightGBM] [Info] Number of data points in the train set: 157728, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score -1.374070\n",
            "[LightGBM] [Info] Start training from score -1.107611\n",
            "[LightGBM] [Info] Start training from score -1.733393\n",
            "[LightGBM] [Info] Start training from score -1.427558\n",
            "LightGBM Test Accuracy: 0.9638\n",
            "\n",
            "Training Hybrid Neural Network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid NN Test Accuracy: 0.8594\n",
            "\n",
            "Training Logistic Regression...\n",
            "Logistic Regression Test Accuracy: 0.7506\n",
            "\n",
            "Training Meta-Learner (Stacking)...\n",
            "\u001b[1m4929/4929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
            "\u001b[1m1233/1233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040588 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3060\n",
            "[LightGBM] [Info] Number of data points in the train set: 157728, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score -1.374070\n",
            "[LightGBM] [Info] Start training from score -1.107611\n",
            "[LightGBM] [Info] Start training from score -1.733393\n",
            "[LightGBM] [Info] Start training from score -1.427558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Learner (Stack) Test Accuracy: 0.9658\n",
            "\u001b[1m1233/1233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "Blended Model Test Accuracy: 0.936\n",
            "\n",
            "==================================================\n",
            "TRAINING COMPLETE - Model Performance Summary\n",
            "==================================================\n",
            "LightGBM:              0.9638\n",
            "Hybrid NN:             0.8594\n",
            "Logistic Regression:   0.7506\n",
            "Meta-Learner (Stack):  0.9658\n",
            "Blended Average:       0.9360\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category, score = predict_safety(\n",
        "    product_name=\"Organic Whole Wheat Bread\",\n",
        "    ingredients_text=\"whole wheat flour, water, yeast, salt, honey\",\n",
        "    energy=240, fat=3, sat_fat=0.5, carbs=45, sugars=4, fiber=5, protein=9, salt=1, sodium=0.4\n",
        ")\n",
        "\n",
        "category, score = predict_safety(\n",
        "    product_name=\"Steamed Quinoa with Vegetables\",\n",
        "    ingredients_text=\"quinoa, spinach, broccoli, carrot, olive oil, lemon juice\",\n",
        "    energy=120, fat=2, sat_fat=0.3, carbs=21, sugars=1.5, fiber=4.5, protein=6, salt=0.3, sodium=0.12\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv-565TOxGEx",
        "outputId": "083653c2-fec8-42bd-c572-d8e015755607"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\n",
            "=== EXAMPLE PREDICTION ===\n",
            "Product: Organic Whole Wheat Bread\n",
            "Predicted Category: Very Healthy\n",
            "Model Confidence: 0.913\n",
            "Safety Score: 9.13/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "=== EXAMPLE PREDICTION ===\n",
            "Product: Steamed Quinoa with Vegetables\n",
            "Predicted Category: Very Healthy\n",
            "Model Confidence: 0.970\n",
            "Safety Score: 9.7/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category, score = predict_safety(\n",
        "    product_name=\"Organic Whole Wheat Bread\",\n",
        "    ingredients_text=\"whole wheat flour, water, yeast, salt, honey\",\n",
        "    energy=240, fat=3, sat_fat=0.5, carbs=45, sugars=4, fiber=5, protein=9, salt=1, sodium=0.4\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf5c3EzSfUpB",
        "outputId": "3cd47b8b-df07-44ee-e78c-67a112745ce7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
            "\n",
            "=== EXAMPLE PREDICTION ===\n",
            "Product: Organic Whole Wheat Bread\n",
            "Predicted Category: Very Healthy\n",
            "Model Confidence: 0.913\n",
            "Safety Score: 9.13/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category, score = predict_safety(\n",
        "    product_name=\"Steamed Quinoa with Vegetables\",\n",
        "    ingredients_text=\"quinoa, spinach, broccoli, carrot, olive oil, lemon juice\",\n",
        "    energy=120, fat=2, sat_fat=0.3, carbs=21, sugars=1.5, fiber=4.5, protein=6, salt=0.3, sodium=0.12\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yraf0vQ1gPSn",
        "outputId": "40b2e107-ef98-4796-9943-0a8f437ae94d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "=== EXAMPLE PREDICTION ===\n",
            "Product: Steamed Quinoa with Vegetables\n",
            "Predicted Category: Very Healthy\n",
            "Model Confidence: 0.970\n",
            "Safety Score: 9.7/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMQq9f0xu5_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}